mutate(analysis_results = pmap(list(generated_data),
analyse_data))
# summarise simulation results over the iterations ----
simulation_c_summary <- simulation_c |>
unnest(analysis_results) |>
group_by(skew_control,skew_intervention)|>
# # \TODO - the summary across conditions must be group_by()'d the conditions that were manipulated, ie where there is more than one value for the parameter in expand_grid()
# group_by() |>
summarize(false_positive_rate = round_half_up(mean(p < .05), digits = 3),
c_d = round_half_up(mean(cohens_d < .05), digits = 3)
# \TODO - this code to summarize the outcomes will need to be adapted
)
# print results table
simulation_c_summary |>
kable() |>
kable_classic(full_width = FALSE)
generate_cor_data <- function(n_,
r_) {
data <-rnorm_multi(
n = n_,
mu = mean_,
sd = sd_,
r = r_,
empirical = TRUE
)
return(data)
}
# remove all objects from environment ----
#rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(effsize)
library(faux)
install.packages("faux")
generate_cor_data <- function(n, r) {
data <- rnorm_multi(
n = n,
mu = c(A = 0, B = 0),
sd = 1,
r = c(1.0, r,
r, 1.0)
)
return(data)
}
generate_cor_data(100, 0.3)
library(faux)
data <- rnorm_multi(
n = n,
mu = c(A = 0, B = 0),
sd = 1,
r = c(1.0, r,
r, 1.0)
)
generate_cor_data <- function(n, r) {
data <- rnorm_multi(
n = n,
mu = c(A = 0, B = 0),
sd = 1,
r = c(1.0, r,
r, 1.0)
)
return(data)
}
generate_cor_data(100, 0.3)
generate_cor_data(100, 0.3)
generate_cor_data(100, 0.3)|>
cor()
# remove all objects from environment ----
#rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(effsize)
library(faux)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(123)
# define data generating function
## r_ <-- die korrelationswerte habe ich
generate_data <- function(n, r) {
data <- rnorm_multi(
n = n,
mu = c(A = 0, B = 0),
sd = 1,
r = c(1.0, r,
r, 1.0)
)
return(data)
}
# to check if it does what it should do
# generate_cor_data(100, 0.3)|>
#   cor()
# es funktioniert auch nur so:
#   r = r #also ohne Matrix!
# define data analysis function ----
analyse_data <- function(data) {
#noch nicht runden!!
#problem = es war kein dataframe!
result1 <- cor(data)
#für die p-values?
result2 <- cor.test(x = data$A, y = data$B)
result <- data.frame(p = result2$p.value,
r = result2$estimate)
return(result)
}
# define experiment parameters ----
experiment_parameters_grid <- expand_grid(
n = seq(seq(25, 400, 25)),
r_ = c(0, 0.3),
iteration = 1:10000)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_cor_data = pmap(list(n_, mean_, sd_, r_),
generate_cor_data)) #|>
analyse_data <- function(data) {
#noch nicht runden!!
#problem = es war kein dataframe!
result1 <- cor(data)
#für die p-values?
result2 <- cor.test(x = data$A, y = data$B)
result <- data.frame(p = result2$p.value,
r_observed = result2$estimate)
return(result)
}
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(sn)
library(knitr)
library(kableExtra)
rsn(n = 100000,
xi = 0,
omega = 1,
alpha = 0) |>
hist(main = "Skew-normal data when alpha is large (0)", xlab = "Score")
# skew-normal ist unter gewissen Parameter gleich wie normal verteilt
rsn(n = 100000,
xi = 0,
omega = 1,
alpha = 0) |>
hist(main = "Skew-normal data when alpha is large (0)", xlab = "Score")
rsn(n = 100000,
xi = 0,
omega = 1,
alpha = 1) |>
hist(main = "Skew-normal data when alpha is large (1)", xlab = "Score")
rsn(n = 100000,
xi = 0,
omega = 1,
alpha = 2) |>
hist(main = "Skew-normal data when alpha is large (2)", xlab = "Score")
rsn(n = 100000,
xi = 0,
omega = 1,
alpha = 3) |>
hist(main = "Skew-normal data when alpha is large (3)", xlab = "Score")
rsn(n = 100000,
xi = 0,
omega = 1,
alpha = 6) |>
hist(main = "Skew-normal data when alpha is large (6)", xlab = "Score")
rsn(n = 100000,
xi = 0,
omega = 1,
alpha = 9) |>
hist(main = "Skew-normal data when alpha is large (9)", xlab = "Score")
rsn(n = 100000,
xi = 0,
omega = 1,
alpha = 12) |>
hist(main = "Skew-normal data when alpha is large (6)", xlab = "Score")
# remove all objects from environment ----
rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(sn)
library(knitr)
library(kableExtra)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)
# define data generating function ----
generate_data <- function(n,
location, # location, akin to mean
scale, # scale, akin to SD
skew) { # slant/skew. When 0, produces normal/gaussian data
data <-
tibble(score = rsn(n = n,
xi = location, # location, akin to mean
omega = scale, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
return(data)
}
# define data analysis function ----
analyse_data <- function(data) {
fit <- ks.test(data$score, "pnorm", mean = mean(data$score), sd = sd(data$score))
results <- tibble(p = fit$p.value)
return(results)
}
# define experiment parameters ----
experiment_parameters_grid <- expand_grid(
n = seq(from = 10, to = 100, by = 10),
location = 0, # location, akin to mean
scale = 1,    # scale, akin to SD
skew = c(0, 1, 2, 3, 6, 9, 12),     # slant/skew. When 0, produces normal/gaussian data
iteration = 1:1000
)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n,
location,
scale,
skew),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data),
analyse_data))
# summarise simulation results over the iterations ----
## ie what proportion of p values are significant (< .05)
simulation_summary <- simulation |>
unnest(analysis_results) |>
mutate(n = as.factor(n)) |>
group_by(n,
location,
scale,
skew) |>
summarize(proportion_of_significant_results = mean(p < .05),
.groups = "drop")
simulation_summary |>
#filter(proportion_of_significant_results >= .8) |>
kable() |>
kable_classic(full_width = FALSE)
_results >= .8) |>
# remove all objects from environment ----
rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(sn)
library(knitr)
library(kableExtra)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)
# define data generating function ----
generate_data <- function(n,
location, # location, akin to mean
scale, # scale, akin to SD
skew) { # slant/skew. When 0, produces normal/gaussian data
data <-
tibble(score = rsn(n = n,
xi = location, # location, akin to mean
omega = scale, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
return(data)
}
# define data analysis function ----
analyse_data <- function(data) {
fit <- shapiro.test(data$score)
results <- tibble(p = fit$p.value)
return(results)
}
# define experiment parameters ----
experiment_parameters_grid <- expand_grid(
n = seq(from = 10, to = 100, by = 10),
location = 0, # location, akin to mean
scale = 1,    # scale, akin to SD
skew = c(0, 1, 2, 3, 6, 9, 12),     # slant/skew. When 0, produces normal/gaussian data
iteration = 1:1000
)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n,
location,
scale,
skew),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data),
analyse_data))
# summarise simulation results over the iterations ----
## ie what proportion of p values are significant (< .05)
simulation_summary <- simulation |>
unnest(analysis_results) |>
mutate(n = as.factor(n)) |>
group_by(n,
location,
scale,
skew) |>
summarize(proportion_of_significant_results = mean(p < .05),
.groups = "drop")
simulation_summary |>
filter(proportion_of_significant_results >= .95) |>
kable() |>
kable_classic(full_width = FALSE)
# remove all objects from environment ----
rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(sn)
library(knitr)
library(kableExtra)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)
# define data generating function ----
generate_data <- function(n,
location_control, # location, akin to mean
location_intervention,
scale, # scale, akin to SD
skew) { # slant/skew. When 0, produces normal/gaussian data
data_control <-
tibble(condition = "control",
score = rsn(n = n,
xi = location_control, # location, akin to mean
omega = scale, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data_intervention <-
tibble(condition = "intervention",
score = rsn(n = n,
xi = location_intervention, # location, akin to mean
omega = scale, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data <- bind_rows(data_control,
data_intervention)
return(data)
}
# define data analysis function ----
analyse_data <- function(data) {
assumption_test_intervention   <- shapiro.test(data$score[data$condition == "intervention"])
assumption_test_control        <- shapiro.test(data$score[data$condition == "control"])
hypothesis_test_welches_t      <- t.test(formula = score ~ condition,
data = data,
var.equal = TRUE,
alternative = "two.sided")
hypothesis_test_mann_whitney_u <- wilcox.test(formula = score ~ condition,
data = data,
alternative = "two.sided")
results <- tibble(
assumption_test_p_intervention = assumption_test_intervention$p.value,
assumption_test_p_control = assumption_test_control$p.value,
hypothesis_test_p_welches_t = hypothesis_test_welches_t$p.value,
hypothesis_test_p_mann_whitney_u = hypothesis_test_mann_whitney_u$p.value
) |>
mutate(hypothesis_test_p_conditional = ifelse(min(assumption_test_p_intervention, assumption_test_p_control) < .05,
hypothesis_test_p_mann_whitney_u,
hypothesis_test_p_welches_t))
return(results)
}
# define experiment parameters ----
experiment_parameters_grid <- expand_grid(
n = seq(from = 10, to = 100, by = 10), # n per condition, not total
location_control = 0, # location, akin to mean
location_intervention = 0.2,
scale = 1,    # scale, akin to SD
skew = c(0, 1, 2, 3, 6, 9, 12),     # slant/skew. When 0, produces normal/gaussian data
iteration = 1:1000
)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n,
location_control,
location_intervention,
scale,
skew),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data),
analyse_data))
# summarise simulation results over the iterations ----
## ie what proportion of p values are significant (< .05)
simulation_summary <- simulation |>
unnest(analysis_results) |>
mutate(n_per_group = as.factor(n)) |>
group_by(n_per_group,
location_control,
location_intervention,
scale,
skew) |>
summarize(power_assumption_test = mean(assumption_test_p_intervention < .05 | assumption_test_p_control < .05),
power_u = mean(hypothesis_test_p_mann_whitney_u < .05),
power_t = mean(hypothesis_test_p_welches_t < .05),
power_u = mean(hypothesis_test_p_mann_whitney_u < .05),
power_conditional = mean(hypothesis_test_p_conditional < .05),
.groups = "drop") |>
mutate(conditional_better_than_t = power_conditional > power_t,
conditional_better_than_u = power_conditional > power_u,
u_better_than_t = power_u > power_t,
conditional_much_better_than_t = (power_conditional - power_t) >= .05,
conditional_much_better_than_u = (power_conditional - power_u) >= .05,
u_much_better_than_t = (power_u - power_t) >= .05)
simulation_summary |>
arrange(skew, n_per_group) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
arrange(skew, n_per_group) |>
select(n_per_group, skew, power_t, power_u, power_conditional, conditional_better_than_t) |>
mutate(power_diff_cond_t = power_conditional - power_t) |>
filter(conditional_better_than_t == TRUE &
power_diff_cond_t >= 0.05) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
arrange(skew, n_per_group) |>
select(n_per_group, skew, power_t, power_u, power_conditional, conditional_better_than_u) |>
mutate(power_diff_cond_u = power_conditional - power_u) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
arrange(skew, n_per_group) |>
select(n_per_group, skew, power_t, power_u, power_conditional, conditional_better_than_t) |>
mutate(power_diff_u_t = power_u - power_t) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
summarize(percent_u_better_than_t = mean(u_better_than_t)*100,
percent_conditional_better_than_t = mean(conditional_better_than_t)*100,
percent_conditional_better_than_u = mean(conditional_better_than_u)*100) |>
mutate_if(is.numeric, janitor::round_half_up, digits = 1) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
summarize(percent_u_much_better_than_t = mean(u_much_better_than_t)*100,
percent_conditional_much_better_than_t = mean(conditional_much_better_than_t)*100,
percent_conditional_much_better_than_u = mean(conditional_much_better_than_u)*100) |>
mutate_if(is.numeric, janitor::round_half_up, digits = 1) |>
kable() |>
kable_classic(full_width = FALSE)
data_for_testing <- generate_data(n = 100,
location = 0,
scale_intervention = 1,
skew= 0)
generate_data <- function(n,
location, # location, akin to mean
scale_intervention, # scale, akin to SD
scale_control,
skew) { # slant/skew. When 0, produces normal/gaussian data
data_intervention <-
tibble(condition = "intervention",
score = rsn(n = n,
xi = location, # location, akin to mean
omega = scale_intervention, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data_control <-
tibble(condition = "control",
score = rsn(n = n,
xi = location, # location, akin to mean
omega = scale_control, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data <- bind_rows(data_intervention,
data_control)
return(data)
}
library(car)
data_for_testing <- generate_data(n = 100,
location = 0,
scale_intervention = 1,
skew= 0)
data_for_testing <- generate_data(n = 100,
location = 0,
scale_intervention = 1,
scale_control = 1,
skew= 0)
result_for_testing <- leveneTest(y = data_for_testing$score,
group = data_for_testing$condition,
center = "median")
data.frame(p=
result_for_testing$`Pr(>F)`[1])
