scale_intervention = c(1.0, 1.1, 1.2, 1.3, 1.4, 1.5), # scale, akin to SD
scale_control = 1, # location, akin to mean
skew = 0, # slant/skew. When 0, produces normal/gaussian data
iteration = 1:1000
)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n,
location,
scale_intervention,
scale_control,
skew),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data),
analyse_data))
simulation_summary <- simulation |>
unnest(analysis_results) |>
group_by(n,
location,
scale_intervention,
scale_control) |>
summarize(proportion_of_significant_results = mean(assumption_test_homogeneity_p < .05),
.groups = "drop")
simulation_summary |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
filter(proportion_of_significant_results >= .95) |>
kable() |>
kable_classic(full_width = FALSE)
# remove all objects from environment ----
rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(sn)
library(knitr)
library(kableExtra)
library(car)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)
# define data generating function ----
generate_data <- function(n,
location_intervention, # location, akin to mean
location_control,
scale_intervention, # scale, akin to SD
scale_control,
skew) { # slant/skew. When 0, produces normal/gaussian data
data_intervention <-
tibble(condition = "intervention",
score = rsn(n = n,
xi = location_intervention, # location, akin to mean
omega = scale_intervention, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data_control <-
tibble(condition = "control",
score = rsn(n = n,
xi = location_control, # location, akin to mean
omega = scale_control, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data <- bind_rows(data_intervention,
data_control)
return(data)
}
# define data analysis function ----
# 2 - The second simulation should calculate the p value from the Bartlett test, and also *both* a **Student's** *t*-test and a Mann-Whitney U test (aka Wilcoxon Rank-Sum test).
# Which hypothesis tests's p value is used to make the statistical inference in each iteration should be determined by whether the assumption test detects a violation or not.
# test_data <- generate_data(100, 0, 0, 1, 1,0)
analyse_data <- function(data) {
require(car)
bartlett_result<- bartlett.test(score ~ condition, data = data)
assumption_test_homogeneity_p <- bartlett_result$p.value
# Initialize placeholders for potential results
hypothesis_test_p_students_t <- NA
hypothesis_test_p_mann_whitney_u <- NA
hypothesis_test_p_conditional <- NA
test_used <- NA
# If Bartlett's test p-value is greater than 0.05, it suggests that variances are equal, and hence, a Student's t-test (assuming equal variances) is appropriate.
# assumption_test_homogeneity_p = 0.003
if (assumption_test_homogeneity_p > 0.05) {
#student's test
ttest_result <- t.test(score ~ condition, data = data, var.equal = TRUE)
hypothesis_test_p_students_t <- ttest_result$p.value
hypothesis_test_p_conditional <- ttest_result$p.value
test_used <- "Student's t-test"
} else{
#Wilcoxon Rank-Sum test
wilcox_result <- wilcox.test(score ~ condition, data = data)
hypothesis_test_p_mann_whitney_u <- wilcox_result$p.value
hypothesis_test_p_conditional <- wilcox_result$p.value
test_used <- "Mann-Whitney U test"
}
results <- tibble(assumption_test_homogeneity_p = assumption_test_homogeneity_p,
hypothesis_test_p_mann_whitney_u = hypothesis_test_p_mann_whitney_u,
hypothesis_test_p_students_t = hypothesis_test_p_students_t,
hypothesis_test_p_conditional = hypothesis_test_p_conditional,
test_used = test_used)
return(results)
}
# define experiment parameters ----
experiment_parameters_grid <- expand_grid(
n = 100, # n per condition, not total
location_intervention = 0.2,
location_control = 0.0,
scale_intervention = c(1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0), # scale, akin to SD
scale_control = 1, # location, akin to mean
skew = c(0, 1, 2, 3, 6, 9, 12), # slant/skew. When 0, produces normal/gaussian data
iteration = 1:1000
)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n,
location_intervention,
location_control,
scale_intervention,
scale_control,
skew),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data),
analyse_data))
# summarise simulation results over the iterations ----
## ie what proportion of p values are significant (< .05)
simulation_summary <- simulation |>
unnest(analysis_results) |>
mutate(n_per_group = as.factor(n)) |>
group_by(n,
location_intervention,
location_control,
scale_intervention,
scale_control,
skew) |>
summarize(power_assumption_test = mean(assumption_test_homogeneity_p < .05),
power_u = mean(hypothesis_test_p_mann_whitney_u < .05),
power_t = mean(hypothesis_test_p_students_t < .05),
power_u = mean(hypothesis_test_p_mann_whitney_u < .05),
power_conditional = mean(hypothesis_test_p_conditional < .05),
.groups = "drop") |>
mutate(conditional_better_than_t = power_conditional > power_t,
conditional_better_than_u = power_conditional > power_u,
u_better_than_t = power_u > power_t,
conditional_much_better_than_t = (power_conditional - power_t) >= .05,
conditional_much_better_than_u = (power_conditional - power_u) >= .05,
u_much_better_than_t = (power_u - power_t) >= .05)
simulation_summary |>
select(n, location_intervention, location_control, scale_intervention, scale_control, skew,
power_assumption_test, power_u, power_t, power_conditional) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
summarize(percent_u_better_than_t = mean(u_better_than_t)*100,
percent_conditional_better_than_t = mean(conditional_better_than_t)*100,
percent_conditional_better_than_u = mean(conditional_better_than_u)*100) |>
mutate_if(is.numeric, janitor::round_half_up, digits = 1) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
summarize(percent_u_much_better_than_t = mean(u_much_better_than_t)*100,
percent_conditional_much_better_than_t = mean(conditional_much_better_than_t)*100,
percent_conditional_much_better_than_u = mean(conditional_much_better_than_u)*100) |>
mutate_if(is.numeric, janitor::round_half_up, digits = 1) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
filter(conditional_much_better_than_t) |>
mutate_if(is.numeric, janitor::round_half_up, digits = 1) |>
kable() |>
kable_classic(full_width = FALSE)
# remove all objects from environment ----
rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(sn)
library(knitr)
library(kableExtra)
library(car)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)
# define data generating function ----
generate_data <- function(n,
location_intervention, # location, akin to mean
location_control,
scale_intervention, # scale, akin to SD
scale_control,
skew) { # slant/skew. When 0, produces normal/gaussian data
data_intervention <-
tibble(condition = "intervention",
score = rsn(n = n,
xi = location_intervention, # location, akin to mean
omega = scale_intervention, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data_control <-
tibble(condition = "control",
score = rsn(n = n,
xi = location_control, # location, akin to mean
omega = scale_control, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data <- bind_rows(data_intervention,
data_control)
return(data)
}
# define data analysis function ----
# 2 - The second simulation should calculate the p value from the Bartlett test, and also *both* a **Student's** *t*-test and a Mann-Whitney U test (aka Wilcoxon Rank-Sum test).
# Which hypothesis tests's p value is used to make the statistical inference in each iteration should be determined by whether the assumption test detects a violation or not.
# test_data <- generate_data(100, 0, 0, 1, 1,0)
analyse_data <- function(data) {
require(car)
bartlett_result<- bartlett.test(score ~ condition, data = data)
assumption_test_homogeneity_p <- bartlett_result$p.value
# Initialize placeholders for potential results
hypothesis_test_p_students_t <- NA
hypothesis_test_p_mann_whitney_u <- NA
hypothesis_test_p_conditional <- NA
test_used <- NA
# If Bartlett's test p-value is greater than 0.05, it suggests that variances are equal, and hence, a Student's t-test (assuming equal variances) is appropriate.
# assumption_test_homogeneity_p = 0.003
if (assumption_test_homogeneity_p > 0.05) {
#student's test
ttest_result <- t.test(score ~ condition, data = data, var.equal = TRUE)
hypothesis_test_p_students_t <- ttest_result$p.value
hypothesis_test_p_conditional <- ttest_result$p.value
test_used <- "Student's t-test"
} else{
#Wilcoxon Rank-Sum test
wilcox_result <- wilcox.test(score ~ condition, data = data)
hypothesis_test_p_mann_whitney_u <- wilcox_result$p.value
hypothesis_test_p_conditional <- wilcox_result$p.value
test_used <- "Mann-Whitney U test"
}
results <- tibble(assumption_test_homogeneity_p = assumption_test_homogeneity_p,
hypothesis_test_p_mann_whitney_u = hypothesis_test_p_mann_whitney_u,
hypothesis_test_p_students_t = hypothesis_test_p_students_t,
hypothesis_test_p_conditional = hypothesis_test_p_conditional,
test_used = test_used)
return(results)
}
# define experiment parameters ----
experiment_parameters_grid <- expand_grid(
n = 100, # n per condition, not total
location_intervention = 0.2,
location_control = 0.0,
scale_intervention = c(1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0), # scale, akin to SD
scale_control = 1, # location, akin to mean
skew = c(0, 1, 2, 3, 6, 9, 12), # slant/skew. When 0, produces normal/gaussian data
iteration = 1:1000
)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n,
location_intervention,
location_control,
scale_intervention,
scale_control,
skew),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data),
analyse_data))
# summarise simulation results over the iterations ----
## ie what proportion of p values are significant (< .05)
simulation_summary <- simulation |>
unnest(analysis_results) |>
mutate(n_per_group = as.factor(n)) |>
group_by(n,
location_intervention,
location_control,
scale_intervention,
scale_control,
skew) |>
summarize(power_assumption_test = mean(assumption_test_homogeneity_p < .05),
power_u = mean(hypothesis_test_p_mann_whitney_u > .05),
power_t = mean(hypothesis_test_p_students_t > .05),
power_u = mean(hypothesis_test_p_mann_whitney_u > .05),
power_conditional = mean(hypothesis_test_p_conditional > .05),
.groups = "drop") |>
mutate(conditional_better_than_t = power_conditional > power_t,
conditional_better_than_u = power_conditional > power_u,
u_better_than_t = power_u > power_t,
conditional_much_better_than_t = (power_conditional - power_t) >= .05,
conditional_much_better_than_u = (power_conditional - power_u) >= .05,
u_much_better_than_t = (power_u - power_t) >= .05)
simulation_summary |>
select(n, location_intervention, location_control, scale_intervention, scale_control, skew,
power_assumption_test, power_u, power_t, power_conditional) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
summarize(percent_u_better_than_t = mean(u_better_than_t)*100,
percent_conditional_better_than_t = mean(conditional_better_than_t)*100,
percent_conditional_better_than_u = mean(conditional_better_than_u)*100) |>
mutate_if(is.numeric, janitor::round_half_up, digits = 1) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
summarize(percent_u_much_better_than_t = mean(u_much_better_than_t)*100,
percent_conditional_much_better_than_t = mean(conditional_much_better_than_t)*100,
percent_conditional_much_better_than_u = mean(conditional_much_better_than_u)*100) |>
mutate_if(is.numeric, janitor::round_half_up, digits = 1) |>
kable() |>
kable_classic(full_width = FALSE)
simulation_summary |>
filter(conditional_much_better_than_t) |>
mutate_if(is.numeric, janitor::round_half_up, digits = 1) |>
kable() |>
kable_classic(full_width = FALSE)
rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(sn)
library(knitr)
library(kableExtra)
library(car)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(42)
# define data generating function ----
generate_data <- function(n,
location_intervention, # location, akin to mean
location_control,
scale_intervention, # scale, akin to SD
scale_control,
skew) { # slant/skew. When 0, produces normal/gaussian data
data_intervention <-
tibble(condition = "intervention",
score = rsn(n = n,
xi = location_intervention, # location, akin to mean
omega = scale_intervention, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data_control <-
tibble(condition = "control",
score = rsn(n = n,
xi = location_control, # location, akin to mean
omega = scale_control, # scale, akin to SD
alpha = skew)) # slant/skew. When 0, produces normal/gaussian data
data <- bind_rows(data_intervention,
data_control)
return(data)
}
# define data analysis function ----
# 2 - The second simulation should calculate the p value from the Bartlett test, and also *both* a **Student's** *t*-test and a Mann-Whitney U test (aka Wilcoxon Rank-Sum test).
# Which hypothesis tests's p value is used to make the statistical inference in each iteration should be determined by whether the assumption test detects a violation or not.
# test_data <- generate_data(100, 0, 0, 1, 1,0)
analyse_data <- function(data) {
require(car)
bartlett_result<- bartlett.test(score ~ condition, data = data)
assumption_test_homogeneity_p <- bartlett_result$p.value
# Initialize placeholders for potential results
hypothesis_test_p_students_t <- NA
hypothesis_test_p_mann_whitney_u <- NA
hypothesis_test_p_conditional <- NA
test_used <- NA
# If Bartlett's test p-value is greater than 0.05, it suggests that variances are equal, and hence, a Student's t-test (assuming equal variances) is appropriate.
# assumption_test_homogeneity_p = 0.003
if (assumption_test_homogeneity_p > 0.05) {
#student's test
ttest_result <- t.test(score ~ condition, data = data, var.equal = TRUE)
hypothesis_test_p_students_t <- ttest_result$p.value
hypothesis_test_p_conditional <- ttest_result$p.value
test_used <- "Student's t-test"
} else{
#Wilcoxon Rank-Sum test
wilcox_result <- wilcox.test(score ~ condition, data = data)
hypothesis_test_p_mann_whitney_u <- wilcox_result$p.value
hypothesis_test_p_conditional <- wilcox_result$p.value
test_used <- "Mann-Whitney U test"
}
results <- tibble(assumption_test_homogeneity_p = assumption_test_homogeneity_p,
hypothesis_test_p_mann_whitney_u = hypothesis_test_p_mann_whitney_u,
hypothesis_test_p_students_t = hypothesis_test_p_students_t,
hypothesis_test_p_conditional = hypothesis_test_p_conditional,
test_used = test_used)
return(results)
}
# define experiment parameters ----
experiment_parameters_grid <- expand_grid(
n = 100, # n per condition, not total
location_intervention = 0.2,
location_control = 0.0,
scale_intervention = c(1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0), # scale, akin to SD
scale_control = 1, # location, akin to mean
skew = c(0, 1, 2, 3, 6, 9, 12), # slant/skew. When 0, produces normal/gaussian data
iteration = 1:1000
)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n,
location_intervention,
location_control,
scale_intervention,
scale_control,
skew),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data),
analyse_data))
data <- generate_data(100,0,0,1,1,0)
artlett_result<- bartlett.test(score ~ condition, data = data)
assumption_test_homogeneity_p <- bartlett_result$p.value
bartlett_result<- bartlett.test(score ~ condition, data = data)
assumption_test_homogeneity_p <- bartlett_result$p.value
# Initialize placeholders for potential results
hypothesis_test_p_students_t <- NA
hypothesis_test_p_mann_whitney_u <- NA
hypothesis_test_p_conditional <- NA
test_used <- NA
# If Bartlett's test p-value is greater than 0.05, it suggests that variances are equal, and hence, a Student's t-test (assuming equal variances) is appropriate.
# assumption_test_homogeneity_p = 0.003
if (assumption_test_homogeneity_p > 0.05) {
#student's test
ttest_result <- t.test(score ~ condition, data = data, var.equal = TRUE)
hypothesis_test_p_students_t <- ttest_result$p.value
hypothesis_test_p_conditional <- ttest_result$p.value
test_used <- "Student's t-test"
} else{
#Wilcoxon Rank-Sum test
wilcox_result <- wilcox.test(score ~ condition, data = data)
hypothesis_test_p_mann_whitney_u <- wilcox_result$p.value
hypothesis_test_p_conditional <- wilcox_result$p.value
test_used <- "Mann-Whitney U test"
}
results <- tibble(assumption_test_homogeneity_p = assumption_test_homogeneity_p,
hypothesis_test_p_mann_whitney_u = hypothesis_test_p_mann_whitney_u,
hypothesis_test_p_students_t = hypothesis_test_p_students_t,
hypothesis_test_p_conditional = hypothesis_test_p_conditional,
test_used = test_used)
View(results)
experiment_parameters_grid <- expand_grid(
n = 100, # n per condition, not total
location_intervention = 0.2,
location_control = 0.0,
scale_intervention = c(1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0), # scale, akin to SD
scale_control = 1, # location, akin to mean
skew = c(0, 1, 2, 3, 6, 9, 12), # slant/skew. When 0, produces normal/gaussian data
iteration = 1:100
)
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n,
location_intervention,
location_control,
scale_intervention,
scale_control,
skew),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data),
analyse_data))
View(simulation)
View(simulation[[9]][[1]])
View(simulation[[8]][[1]])
simulation_summary <- simulation |>
unnest(analysis_results) |>
mutate(n_per_group = as.factor(n)) |>
group_by(n,
location_intervention,
location_control,
scale_intervention,
scale_control,
skew) |>
summarize(power_assumption_test = mean(assumption_test_homogeneity_p < .05),
power_u = mean(hypothesis_test_p_mann_whitney_u < .05),
power_t = mean(hypothesis_test_p_students_t < .05),
power_u = mean(hypothesis_test_p_mann_whitney_u < .05),
power_conditional = mean(hypothesis_test_p_conditional < .05),
.groups = "drop") |>
mutate(conditional_better_than_t = power_conditional > power_t,
conditional_better_than_u = power_conditional > power_u,
u_better_than_t = power_u > power_t,
conditional_much_better_than_t = (power_conditional - power_t) >= .05,
conditional_much_better_than_u = (power_conditional - power_u) >= .05,
u_much_better_than_t = (power_u - power_t) >= .05)
View(simulation_summary)
